{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Micro-Laboratorio (Ejercicio Pr√°ctico)\n",
        "\n",
        "**Consigna:** (Asumiendo que `word_vectors` se carg√≥ correctamente)\n",
        "\n",
        "1.  **Exploraci√≥n de Similitud:**\n",
        "    *   Elegir 5 palabras que les interesen (intenten variar: un lugar, una profesi√≥n, un concepto abstracto, una comida, un sentimiento).\n",
        "    *   Para cada una, usar `word_vectors.most_similar()` para encontrar las 5 palabras m√°s parecidas.\n",
        "    *   Anotar los resultados. ¬øLes parecen l√≥gicos? ¬øHay alguna similitud sorprendente o extra√±a?\n",
        "\n",
        "2.  **Prueba de Analog√≠as:**\n",
        "    *   Inventar y probar 3 analog√≠as diferentes usando `word_vectors.most_similar(positive=[...], negative=[...])`.\n",
        "    *   Ideas:\n",
        "        *   `programador` es a `computadora` como `m√©dico` es a `?`\n",
        "        *   `Argentina` es a `peso` como `Jap√≥n` es a `?`\n",
        "        *   `caminar` es a `pierna` como `hablar` es a `?`\n",
        "    *   Verificar que todas las palabras de la analog√≠a est√©n en el vocabulario antes de probarla.\n",
        "    *   Anotar los resultados. ¬øFuncionan las analog√≠as como esperaban?\n",
        "\n",
        "3.  **(Opcional) Medir Similitud:**\n",
        "    *   Elegir 3 pares de palabras:\n",
        "        *   Un par de sin√≥nimos claros (ej: `estudiante`, `alumno`).\n",
        "        *   Un par de ant√≥nimos (ej: `grande`, `peque√±o`).\n",
        "        *   Un par de palabras no relacionadas (ej: `nube`, `zapato`).\n",
        "    *   Calcular `word_vectors.similarity()` para cada par.\n",
        "    *   ¬øLos valores de similitud reflejan la relaci√≥n entre las palabras? (Esperamos alta para sin√≥nimos, baja/media-baja para no relacionadas, y ¬øqu√© pasa con ant√≥nimos?).\n",
        "\n",
        "**¬°Aseg√∫rense de que las palabras que usan existan en `word_vectors`!**"
      ],
      "metadata": {
        "id": "nC63WVgQSvzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos la librer√≠a gensim, necesaria para cargar y usar word embeddings\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Va1H86X7zjm",
        "outputId": "76c29a99-efea-40d1-a19d-5eebb52f73bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå Este archivo en realidad es de FastText, pero tambi√©n se puede usar con Gensim como si fuera Word2Vec."
      ],
      "metadata": {
        "id": "cf1bQl7kO1DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos modelo preentrenado del SBWC en formato binario\n",
        "!wget -O sbwc_spanish.bin https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
        "!gunzip sbwc_spanish.bin.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpf3MR3pOwWk",
        "outputId": "3fc3b027-758c-4e14-d5bd-5f642671e3f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-18 18:18:56--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.108, 3.163.189.96, 3.163.189.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1285580896 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‚Äòsbwc_spanish.bin‚Äô\n",
            "\n",
            "sbwc_spanish.bin    100%[===================>]   1.20G  73.2MB/s    in 16s     \n",
            "\n",
            "2025-06-18 18:19:12 (78.4 MB/s) - ‚Äòsbwc_spanish.bin‚Äô saved [1285580896/1285580896]\n",
            "\n",
            "gzip: sbwc_spanish.bin.gz: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar modelo FastText en espa√±ol preentrenado por Facebook (formato .vec.gz)\n",
        "!wget -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\"\n",
        "\n",
        "# Descomprimir\n",
        "!gunzip -f cc.es.300.vec.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo5FPsVKOx8w",
        "outputId": "7397034a-a3d4-46f2-9f90-c0b5795542cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-18 18:19:12--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.108, 3.163.189.96, 3.163.189.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1285580896 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‚Äòcc.es.300.vec.gz‚Äô\n",
            "\n",
            "cc.es.300.vec.gz    100%[===================>]   1.20G   114MB/s    in 15s     \n",
            "\n",
            "2025-06-18 18:19:27 (80.0 MB/s) - ‚Äòcc.es.300.vec.gz‚Äô saved [1285580896/1285580896]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Cargar el modelo descomprimido como texto (binary=False)\n",
        "word_vectors = KeyedVectors.load_word2vec_format(\"cc.es.300.vec\", binary=False)\n",
        "print(\"Modelo en espa√±ol cargado con √©xito.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShahepYXPP2z",
        "outputId": "2b2448e6-9dcc-4eaa-c630-605aeaa6ffc4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo en espa√±ol cargado con √©xito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç **Similitud**"
      ],
      "metadata": {
        "id": "eAt_fCWuThpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras = [\"Argentina\", \"m√©dico\", \"amor\", \"empanada\", \"libertad\"]\n",
        "\n",
        "for palabra in palabras:\n",
        "    if palabra in word_vectors:\n",
        "        similares = word_vectors.most_similar(palabra, topn=5)\n",
        "        print(f\"\\nPalabra: {palabra}\")\n",
        "        for s in similares:\n",
        "            print(f\"  - {s[0]} (Similitud: {s[1]:.2f})\")\n",
        "    else:\n",
        "        print(f\"\\nLa palabra '{palabra}' no est√° en el vocabulario.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0eu-gBaPW6l",
        "outputId": "1eecc9b0-5142-4c74-b157-7cec55d0ee65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palabra: Argentina\n",
            "  - argentina (Similitud: 0.74)\n",
            "  - Uruguay (Similitud: 0.74)\n",
            "  - Aires (Similitud: 0.72)\n",
            "  - Argentina.En (Similitud: 0.72)\n",
            "  - Argentina.2 (Similitud: 0.71)\n",
            "\n",
            "Palabra: m√©dico\n",
            "  - medico (Similitud: 0.82)\n",
            "  - elm√©dico (Similitud: 0.77)\n",
            "  - cardi√≥logo (Similitud: 0.72)\n",
            "  - facultativo (Similitud: 0.72)\n",
            "  - m√©dico.El (Similitud: 0.71)\n",
            "\n",
            "Palabra: amor\n",
            "  - amor.Amor (Similitud: 0.74)\n",
            "  - Amor (Similitud: 0.71)\n",
            "  - desamor (Similitud: 0.69)\n",
            "  - amor.El (Similitud: 0.69)\n",
            "  - amor.Pero (Similitud: 0.69)\n",
            "\n",
            "Palabra: empanada\n",
            "  - empanadita (Similitud: 0.75)\n",
            "  - empanadas (Similitud: 0.71)\n",
            "  - empanadilla (Similitud: 0.71)\n",
            "  - empana (Similitud: 0.67)\n",
            "  - Empanada (Similitud: 0.66)\n",
            "\n",
            "Palabra: libertad\n",
            "  - lalibertad (Similitud: 0.78)\n",
            "  - liberdad (Similitud: 0.71)\n",
            "  - libertad.La (Similitud: 0.70)\n",
            "  - libertdad (Similitud: 0.68)\n",
            "  - Libertad (Similitud: 0.68)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† **Analog√≠as**"
      ],
      "metadata": {
        "id": "fV0tGBIhTk79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analogias = [\n",
        "    ([\"programador\", \"hospital\"], [\"m√©dico\"]),\n",
        "    ([\"Argentina\", \"yen\"], [\"Jap√≥n\"]),\n",
        "    ([\"caminar\", \"boca\"], [\"pierna\"])\n",
        "]\n",
        "\n",
        "for pos, neg in analogias:\n",
        "    try:\n",
        "        result = word_vectors.most_similar(positive=pos, negative=neg, topn=1)\n",
        "        print(f\"\\nAnalog√≠a: {pos[0]} es a {neg[0]} como {pos[1]} es a {result[0][0]}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt8i547-PYy0",
        "outputId": "020722c1-8954-47f5-8f8a-c35e6a90cca4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analog√≠a: programador es a m√©dico como hospital es a programadores\n",
            "\n",
            "Analog√≠a: Argentina es a Jap√≥n como yen es a dolar\n",
            "\n",
            "Analog√≠a: caminar es a pierna como boca es a caminarse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìè **Similitud entre pares**"
      ],
      "metadata": {
        "id": "dD04lwvATpeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pares = [\n",
        "    (\"estudiante\", \"alumno\"),    # sin√≥nimos\n",
        "    (\"grande\", \"peque√±o\"),       # ant√≥nimos\n",
        "    (\"nube\", \"zapato\")           # no relacionadas\n",
        "]\n",
        "\n",
        "for w1, w2 in pares:\n",
        "    if w1 in word_vectors and w2 in word_vectors:\n",
        "        sim = word_vectors.similarity(w1, w2)\n",
        "        print(f\"Similitud entre '{w1}' y '{w2}': {sim:.2f}\")\n",
        "    else:\n",
        "        print(f\"Una de las palabras no est√° en el vocabulario: {w1}, {w2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkKiD8m-Pa0a",
        "outputId": "cd7c8350-9386-4446-a40f-7238a2d9faf3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similitud entre 'estudiante' y 'alumno': 0.74\n",
            "Similitud entre 'grande' y 'peque√±o': 0.59\n",
            "Similitud entre 'nube' y 'zapato': 0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otro ejemplo con EMOCIONES"
      ],
      "metadata": {
        "id": "jKa8waLiUKUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de emociones para explorar\n",
        "emociones = ['alegr√≠a', 'tristeza', 'enojo', 'miedo', 'amor', 'odio', 'sorpresa', 'ansiedad', 'calma', 'felicidad']\n",
        "\n",
        "print(\"üîç Palabras m√°s similares a emociones:\")\n",
        "for emocion in emociones:\n",
        "    if emocion in word_vectors:\n",
        "        similares = word_vectors.most_similar(emocion, topn=5)\n",
        "        print(f\"\\nüß† Emoci√≥n: {emocion}\")\n",
        "        for palabra, score in similares:\n",
        "            print(f\"   - {palabra} ({score:.2f})\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è La palabra '{emocion}' no est√° en el vocabulario del modelo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxf1RJzUiuA",
        "outputId": "c12dc072-e0a8-486d-a5dc-9eebb481f2e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Palabras m√°s similares a emociones:\n",
            "\n",
            "üß† Emoci√≥n: alegr√≠a\n",
            "   - alegria (0.80)\n",
            "   - j√∫bilo (0.73)\n",
            "   - emoci√≥n (0.72)\n",
            "   - alegr√≠a.Y (0.71)\n",
            "   - laalegr√≠a (0.71)\n",
            "\n",
            "üß† Emoci√≥n: tristeza\n",
            "   - melancol√≠a (0.79)\n",
            "   - congoja (0.78)\n",
            "   - amargura (0.77)\n",
            "   - angustia (0.75)\n",
            "   - desaz√≥n (0.74)\n",
            "\n",
            "üß† Emoci√≥n: enojo\n",
            "   - enfado (0.79)\n",
            "   - ira (0.71)\n",
            "   - resentimiento (0.69)\n",
            "   - Enojo (0.67)\n",
            "   - disgusto (0.66)\n",
            "\n",
            "üß† Emoci√≥n: miedo\n",
            "   - temor (0.85)\n",
            "   - pavor (0.79)\n",
            "   - miedo.Miedo (0.75)\n",
            "   - p√°nico (0.73)\n",
            "   - Miedo (0.73)\n",
            "\n",
            "üß† Emoci√≥n: amor\n",
            "   - amor.Amor (0.74)\n",
            "   - Amor (0.71)\n",
            "   - desamor (0.69)\n",
            "   - amor.El (0.69)\n",
            "   - amor.Pero (0.69)\n",
            "\n",
            "üß† Emoci√≥n: odio\n",
            "   - rencor (0.77)\n",
            "   - resentimiento (0.73)\n",
            "   - fanatismo (0.68)\n",
            "   - odio.El (0.67)\n",
            "   - odio.Y (0.66)\n",
            "\n",
            "üß† Emoci√≥n: sorpresa\n",
            "   - sopresa (0.88)\n",
            "   - Sorpresa (0.73)\n",
            "   - sorpesa (0.73)\n",
            "   - sorpresa.Y (0.71)\n",
            "   - sorpresa.La (0.70)\n",
            "\n",
            "üß† Emoci√≥n: ansiedad\n",
            "   - angustia (0.78)\n",
            "   - laansiedad (0.77)\n",
            "   - ansieda (0.75)\n",
            "   - ansiedad.La (0.70)\n",
            "   - nerviosismo (0.70)\n",
            "\n",
            "üß† Emoci√≥n: calma\n",
            "   - serenidad (0.77)\n",
            "   - tranquilidad (0.76)\n",
            "   - calma. (0.68)\n",
            "   - quietud (0.68)\n",
            "   - calmada (0.68)\n",
            "\n",
            "üß† Emoci√≥n: felicidad\n",
            "   - Felicidad (0.71)\n",
            "   - infelicidad (0.71)\n",
            "   - felicidad.La (0.70)\n",
            "   - lafelicidad (0.70)\n",
            "   - alegr√≠a (0.69)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Similitud sem√°ntica entre emociones\n",
        "‚úÖ 1. Coherencia sem√°ntica\n",
        "\n",
        "El modelo logra identificar palabras muy coherentes y relacionadas con cada emoci√≥n:\n",
        "\n",
        "- alegr√≠a se relaciona con j√∫bilo, emoci√≥n, laalegr√≠a ‚Üí todas expresan estados positivos intensos.\n",
        "\n",
        "- tristeza se asocia con melancol√≠a, congoja, amargura, angustia ‚Üí matices distintos del dolor emocional.\n",
        "\n",
        "- enojo con enfado, ira, resentimiento ‚Üí refleja bien el campo de la ira y su intensidad.\n",
        "\n",
        "Esto confirma que los embeddings captan la dimensi√≥n emocional y sus sin√≥nimos/contextos.\n",
        "\n",
        "‚úÖ 2. Asociaci√≥n con variantes y errores ortogr√°ficos\n",
        "\n",
        "Palabras como alegr√≠a.Y, amor.Pero, sorpresa.La o laansiedad surgen probablemente de haber sido extra√≠das directamente de textos mal segmentados o con puntuaci√≥n no depurada.\n",
        "\n",
        "‚û°Ô∏è Esto sugiere que:\n",
        "\n",
        "El modelo fue entrenado sobre datos reales (lo cual es positivo),\n",
        "\n",
        "Pero tambi√©n revela la necesidad de limpiar mejor los datos para evitar \"ruido textual\".\n",
        "\n",
        "‚úÖ 3. Emociones opuestas o contrastantes\n",
        "\n",
        "- amor aparece vinculado a desamor y amor.Amor, lo que indica que el modelo reconoce incluso relaciones de contraste sem√°ntico dentro del mismo campo emocional.\n",
        "\n",
        "- odio con rencor, resentimiento, fanatismo muestra una visi√≥n profunda del concepto, m√°s all√° del sin√≥nimo literal.\n",
        "\n",
        "‚úÖ 4. Emociones compuestas y relacionadas\n",
        "- ansiedad se conecta con angustia, nerviosismo, lo cual es esperable cl√≠nicamente y ling√º√≠sticamente.\n",
        "\n",
        "- calma con serenidad, tranquilidad, quietud ‚Üí emociones de relajaci√≥n bien agrupadas.\n",
        "\n",
        "- felicidad aparece asociada a alegr√≠a pero tambi√©n a infelicidad, lo que sugiere que el modelo comprende el contraste.\n",
        "\n"
      ],
      "metadata": {
        "id": "TZhs9kJuWqxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo FastText en espa√±ol tiene una capacidad robusta para representar emociones. No solo agrupa sin√≥nimos, sino que capta matices, contrastes y contextos emocionales. Aunque hay algo de \"ruido\" por segmentaci√≥n deficiente, el n√∫cleo sem√°ntico est√° bien definido."
      ],
      "metadata": {
        "id": "t505Z9ldWuyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîÑ Analog√≠as con emociones:\")\n",
        "\n",
        "# Ejemplo 1: amor es a felicidad como odio es a ?\n",
        "if all(p in word_vectors for p in ['amor', 'felicidad', 'odio']):\n",
        "    resultado = word_vectors.most_similar(positive=['odio', 'felicidad'], negative=['amor'], topn=1)\n",
        "    print(f\"amor : felicidad :: odio : {resultado[0][0]} ({resultado[0][1]:.2f})\")\n",
        "\n",
        "# Ejemplo 2: ansiedad es a miedo como calma es a ?\n",
        "if all(p in word_vectors for p in ['ansiedad', 'miedo', 'calma']):\n",
        "    resultado = word_vectors.most_similar(positive=['calma', 'miedo'], negative=['ansiedad'], topn=1)\n",
        "    print(f\"ansiedad : miedo :: calma : {resultado[0][0]} ({resultado[0][1]:.2f})\")\n",
        "\n",
        "# Ejemplo 3: alegr√≠a es a sorpresa como tristeza es a ?\n",
        "if all(p in word_vectors for p in ['alegr√≠a', 'sorpresa', 'tristeza']):\n",
        "    resultado = word_vectors.most_similar(positive=['tristeza', 'sorpresa'], negative=['alegr√≠a'], topn=1)\n",
        "    print(f\"alegr√≠a : sorpresa :: tristeza : {resultado[0][0]} ({resultado[0][1]:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdgvSEX9Ukzp",
        "outputId": "a7cca718-deb3-4f82-d489-11c339979589"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Analog√≠as con emociones:\n",
            "amor : felicidad :: odio : infelicidad (0.61)\n",
            "ansiedad : miedo :: calma : tranquilidad (0.56)\n",
            "alegr√≠a : sorpresa :: tristeza : sopresa (0.67)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo agrupa emociones por su carga fisiol√≥gica y conductual, lo que es muy valioso si quisieras construir un clasificador de estados emocionales por ejemplo."
      ],
      "metadata": {
        "id": "mhXt6dImXUMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pares_emociones = [\n",
        "    ('alegr√≠a', 'felicidad'),    # sin√≥nimos\n",
        "    ('amor', 'odio'),            # ant√≥nimos\n",
        "    ('ansiedad', 'tristeza'),    # relacionadas\n",
        "    ('alegr√≠a', 'miedo'),        # no muy relacionadas\n",
        "]\n",
        "\n",
        "print(\"\\nüìè Similitud entre pares de emociones:\")\n",
        "for w1, w2 in pares_emociones:\n",
        "    if w1 in word_vectors and w2 in word_vectors:\n",
        "        sim = word_vectors.similarity(w1, w2)\n",
        "        print(f\"{w1} ‚Üî {w2}: {sim:.2f}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Palabra faltante: {w1}, {w2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__wzLhclUljb",
        "outputId": "895a44dc-2958-4f77-8926-85fed578b18a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìè Similitud entre pares de emociones:\n",
            "alegr√≠a ‚Üî felicidad: 0.69\n",
            "amor ‚Üî odio: 0.57\n",
            "ansiedad ‚Üî tristeza: 0.59\n",
            "alegr√≠a ‚Üî miedo: 0.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- alegr√≠a ‚Üî felicidad: 0.69 ‚Üí Las palabras \"alegr√≠a\" y \"felicidad\" son bastante similares, ya que son sin√≥nimos, por lo que el valor 0.69 es alto, pero no perfecto (lo que podr√≠a ser por el contexto o las variaciones de uso).\n",
        "\n",
        "- amor ‚Üî odio: 0.57 ‚Üí Aunque \"amor\" y \"odio\" son ant√≥nimos, el valor 0.57 no es tan bajo como podr√≠a esperarse, lo que sugiere que las palabras est√°n en alg√∫n punto intermedio (puede ser que ambas emociones est√©n relacionadas con el concepto de \"fuerza emocional\", aunque sean opuestas).\n",
        "\n",
        "- ansiedad ‚Üî tristeza: 0.59 ‚Üí \"Ansiedad\" y \"tristeza\" est√°n relacionadas, ambas son emociones negativas, por lo que el valor 0.59 muestra una relaci√≥n moderada.\n",
        "\n",
        "- alegr√≠a ‚Üî miedo: 0.38 ‚Üí \"Alegr√≠a\" y \"miedo\" son menos relacionadas que las otras combinaciones, lo que se refleja en el valor 0.38. Aunque ambos son estados emocionales, son bastante diferentes en naturaleza, lo que explica el valor bajo de similitud."
      ],
      "metadata": {
        "id": "4XM-MOl9X2iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Brainstorming: Sesgos en Embeddings\n",
        "\n",
        "Hemos visto que los embeddings capturan relaciones del lenguaje tal como aparecen en los datos de entrenamiento (el corpus masivo).\n",
        "\n",
        "**Pregunta clave:** Si esos datos contienen **sesgos sociales** (de g√©nero, raciales, de profesi√≥n, etc.), ¬øqu√© creen que pasar√° con los embeddings?\n",
        "\n",
        "*   ¬øSe reflejar√°n esos sesgos en las relaciones entre vectores? (Pista: ¬°S√≠!)\n",
        "    *   Ejemplo famoso: `doctor - hombre + mujer = ?` a veces da `enfermera` en modelos entrenados en textos antiguos o sesgados. `programador - hombre + mujer = ?` pod√≠a dar `ama de casa`.\n",
        "*   ¬øQu√© implicancias tiene esto si usamos estos embeddings para tareas como selecci√≥n de personal, an√°lisis de opiniones, o generaci√≥n de texto?\n",
        "*   Si el corpus no representa bien la diversidad ling√º√≠stica (dialectos, jergas, lenguaje inclusivo), ¬øc√≥mo afectar√° eso a los embeddings de esas palabras (si es que existen)?\n",
        "*   **¬øC√≥mo podemos entrenar word embeddings que sean m√°s inclusivos y representativos?** ¬øEs posible \"limpiar\" o \"corregir\" (debias) los embeddings pre-entrenados? ¬øEs nuestra responsabilidad como desarrolladores ser conscientes de esto y mitigarlo?\n",
        "\n",
        "**(Discusi√≥n en grupo)**"
      ],
      "metadata": {
        "id": "VtyameEOTEXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Impacto de los Sesgos en los Embeddings**\n",
        "Los embeddings son representaciones vectoriales de palabras basadas en grandes corpus de texto. Si el corpus contiene sesgos, los embeddings tambi√©n los reflejar√°n. Por ejemplo:\n",
        "\n",
        "- G√©nero: Las palabras \"doctor\" y \"enfermera\" podr√≠an estar m√°s asociadas con \"hombre\" y \"mujer\", respectivamente, si el corpus de texto tiene una visi√≥n tradicional de los roles de g√©nero.\n",
        "\n",
        "- Raza o etnia: Las palabras relacionadas con ciertas razas o etnias podr√≠an ser asociadas con estereotipos negativos si est√°n presentes en los datos de entrenamiento.\n",
        "\n"
      ],
      "metadata": {
        "id": "0eSAKwOUYOHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Implicancias en Tareas Espec√≠ficas**\n",
        "\n",
        "- Selecci√≥n de Personal: Si usamos embeddings sesgados, el modelo podr√≠a preferir ciertos g√©neros o razas para ciertos trabajos (por ejemplo, \"hombre\" para programador o \"mujer\" para enfermera), lo que ser√≠a discriminatorio.\n",
        "\n",
        "- An√°lisis de Opiniones: Si el modelo detecta patrones sesgados, podr√≠a interpretar de manera incorrecta las opiniones sobre ciertos grupos o individuos.\n",
        "\n",
        "- Generaci√≥n de Texto: El sesgo en la generaci√≥n de texto podr√≠a llevar a que el modelo genere respuestas sesgadas, reforzando estereotipos y prejuicios."
      ],
      "metadata": {
        "id": "L36-tVa5YR1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **C√≥mo Afecta la Diversidad Ling√º√≠stica**\n",
        "\n",
        "Si el corpus no representa bien la diversidad ling√º√≠stica, es decir, no incluye diferentes dialectos, jergas o lenguaje inclusivo, los embeddings no ser√°n adecuados para esas variantes ling√º√≠sticas. Esto puede resultar en representaciones incorrectas o incompletas para palabras de comunidades no representadas en el corpus."
      ],
      "metadata": {
        "id": "U62ndsMhYcOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **¬øC√≥mo Solucionar el Problema?**\n",
        "\n",
        "Como se podrian mitigar los sesgos en los embeddings:\n",
        "\n",
        "a. Preprocesamiento de Datos\n",
        "\n",
        "Antes de entrenar los embeddings, puedes intentar limpiar el corpus de datos eliminando o equilibrando las representaciones sesgadas. Esto puede implicar:\n",
        "\n",
        "- Remover frases que refuercen estereotipos.\n",
        "\n",
        "- A√±adir datos que representen mejor la diversidad.\n",
        "\n",
        "b. Entrenar Embeddings Debiasados\n",
        "\n",
        "Puedes usar t√©cnicas para hacer que los embeddings sean m√°s inclusivos y representativos:\n",
        "\n",
        "- Debiasing Methods: Existen m√©todos como Hard Debiasing y Soft Debiasing que intentan \"eliminar\" el sesgo de los embeddings despu√©s de que han sido entrenados.\n",
        "\n",
        "- Ajuste fino (Fine-tuning): Puedes realizar un ajuste fino en el modelo utilizando datos m√°s diversos y equilibrados para reducir los sesgos.\n",
        "\n",
        "c. Inclusi√≥n de Diversidad en el Corpus\n",
        "\n",
        "Una soluci√≥n m√°s a largo plazo ser√≠a entrenar los embeddings con datos que reflejen mejor la diversidad ling√º√≠stica. Esto incluye:\n",
        "\n",
        "- Lenguaje inclusivo.\n",
        "\n",
        "- Variedad de dialectos y jergas.\n",
        "\n",
        "- Datos representativos de diferentes culturas, g√©neros, y etnias.\n",
        "\n",
        "d. Evaluaci√≥n y Monitoreo Continuo\n",
        "\n",
        "Es importante evaluar y monitorear los embeddings continuamente. Puedes usar m√©tricas para evaluar los sesgos y asegurarte de que no est√©n introduciendo discriminaci√≥n o estereotipos.\n",
        "\n",
        "e. Responsabilidad como Desarrolladores\n",
        "\n",
        "S√≠, es nuestra responsabilidad como desarrolladores ser conscientes de estos sesgos. Como creadores de IA, debemos considerar la √©tica y la equidad en el dise√±o de nuestros modelos y datos. Esto no solo mejora la calidad de nuestros modelos, sino que tambi√©n evita que la tecnolog√≠a refuerce o amplifique desigualdades sociales."
      ],
      "metadata": {
        "id": "0ErLRcC8YgQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. C√≥digo Ejemplo -- para **Detectar Sesgos**"
      ],
      "metadata": {
        "id": "SWjhAg7wY4LI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Par de palabras que podr√≠an mostrar sesgo (ejemplo cl√°sico de g√©nero)\n",
        "pares_de_analisis = [\n",
        "    ('doctor', 'hombre', 'mujer', 'enfermera'),\n",
        "    ('programador', 'hombre', 'mujer', 'ama de casa')\n",
        "]\n",
        "\n",
        "print(\"\\nüìè Analizando sesgos de g√©nero en embeddings:\")\n",
        "for palabra1, palabra2, palabra3, palabra4 in pares_de_analisis:\n",
        "    if palabra1 in word_vectors and palabra2 in word_vectors and palabra3 in word_vectors and palabra4 in word_vectors:\n",
        "        # Calcular la operaci√≥n: palabra1 - palabra2 + palabra3\n",
        "        resultado = word_vectors.similarity(palabra1, palabra2) - word_vectors.similarity(palabra1, palabra3) + word_vectors.similarity(palabra1, palabra4)\n",
        "        print(f\"{palabra1} - {palabra2} + {palabra3} = {resultado:.2f}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Algunas palabras faltan en los embeddings: {palabra1}, {palabra2}, {palabra3}, {palabra4}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRF-e35RY0aP",
        "outputId": "ad7d7943-645b-45de-815f-e93bd6b80264"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìè Analizando sesgos de g√©nero en embeddings:\n",
            "doctor - hombre + mujer = 0.56\n",
            "‚ö†Ô∏è Algunas palabras faltan en los embeddings: programador, hombre, mujer, ama de casa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los **embeddings** reflejan los patrones de los datos de entrenamiento, y si esos datos contienen sesgos sociales, estos se reflejar√°n en los embeddings. Para mitigar esto, es fundamental trabajar con datos m√°s representativos y ser conscientes de los sesgos para evitar consecuencias negativas."
      ],
      "metadata": {
        "id": "jord3Et0ZFTV"
      }
    }
  ]
}